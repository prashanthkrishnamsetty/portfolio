---
title: "Data Engineer "
description: "Grorich Tentsystems"
dateString: April 2020 - December 2021
draft: false
tags: ["Python", "R", "SQL", "Tableau"]
showToc: false
weight: 301

--- 

## Description
- Successfully gathered and extracted data from various sources like databases, APIs, and spreadsheets, ensuring a streamlined approach for analysis and implemented efficient data storage strategies on Amazon S3, optimizing file formats and partitioning for enhanced query performance, reducing data retrieval times by 25%.
- Engineered end-to-end ETL workflows using AWS Glue, automating data extraction, transformation, and loading processes, resulting in a 20% reduction in ETL development time.
- Orchestrated and managed large-scale data processing tasks using Amazon EMR, leveraging distributed computing frameworks like Apache Spark to process petabytes of data, resulting in a 30% reduction in processing time.
- Designed and maintained data warehouses on Amazon Redshift, optimizing schema design and query performance, leading to a 25% improvement in analytical processing speed.
- Streamlined data workflows by orchestrating and automating intricate processes with Apache Airflow, resulting in a notable 30% improvement in task efficiency and implemented DAGâ€™s (directed acyclic graphs) for seamless management of dependencies, contributing to a 25% reduction in data processing errors.
- Implemented Terraform to define and manage infrastructure configurations as code, resulting in a 20% reduction in deployment inconsistencies and ensuring a reproducible environment across diverse settings.
- Administered and optimized relational databases using Amazon RDS, enhancing database performance, and ensuring seamless integration with data processing workflows and implemented real-time data streaming and processing using Amazon Kinesis, enabling immediate insights into data changes, and facilitating dynamic adjustments in response to evolving business needs.
- Developed and deployed PySpark applications on Amazon EMR, harnessing the capabilities of distributed computing for large-scale data processing and analysis.
- Designed and enforced referential integrity in the data engineering project by implementing foreign key constraints and defining relationships between key tables. This included incorporating checks during ETL processes to ensure that data adhered to established relationships, minimizing data inconsistencies.
- Implemented automated data validation checks within the data engineering pipeline, encompassing constraints for uniqueness, data types, and cardinality. Real-time monitoring and alerting were integrated to promptly identify and address data quality issues, thereby enhancing the overall reliability and accuracy of the data.
- Demonstrated proficiency in Airflow to create flexible and scalable ETL pipelines, leading to a 20% optimization in both scheduling and execution of data processing jobs


<!-- - Conducted in-depth analysis of datasets using Python resulting in a 20% improvement in data quality and accuracy.
- Cleaned and standardized records, by reducing data entry errors by 40% and enhancing data integrity.
- Implemented data validation checks, reducing data discrepancies by 20% and ensuring high data accuracy.
- Developed and maintained 10+ complex SQL queries, optimizing data retrieval time by 30% and reducing database load.
- Created and presented 20+ interactive data visualizations using Tableau, improving data accessibility and understanding for stakeholders.
- Conducted A/B tests to optimize user engagement and analyzed results using R to make data-driven decisions.
- Managed key performance indicators (KPIs) and created interactive Tableau dashboards, contributing to a 15% enhancement in data-driven decision-making.
- Collaborated with cross-functional teams, including developers and business analysts, ensuring data-driven decisions and timely project deliveries.
- Assisted in generating daily, weekly, and monthly reports for senior management, ensuring accurate and timely information for decision-making. -->

